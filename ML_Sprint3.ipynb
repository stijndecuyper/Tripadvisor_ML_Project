{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stijndecuyper/Tripadvisor_ML_Project/blob/main/ML_Sprint3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08kYJ8FOacma"
      },
      "source": [
        "# Machinaal leren: groep 12 - Sprint 3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbG1hBnsH0t-",
        "outputId": "e6951d58-78ea-4588-8e91-c1171ddcd9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SVjzMPR6tdy"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwMNPOMV6u9K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import string\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dropout\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pickle\n",
        "import gc\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H1rkd-a6ok1"
      },
      "source": [
        "# Getting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxXTFAcf6rEH"
      },
      "outputs": [],
      "source": [
        "restaurant_df = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/restaurant_listings.csv\")\n",
        "review_df = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/reviews.csv\")\n",
        "restaurant_coor_df = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/adressen.csv\")\n",
        "joined_df = pd.read_csv(\"/content/drive/MyDrive/MachineLearning/joined_images_df.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6u8DVR1DkBp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAVP1yyICqdP"
      },
      "source": [
        "# Possible tasks:\n",
        "\n",
        "- Predict the price of a restaurant, based on the distance to the closest parking. (Gent only)\n",
        "    - Gent has a lot of open datasets. We searched for datasets that included factors that are important for us, when searching for a restaurant. We choose for Parking.\n",
        "\n",
        "- Improve the clustering model of sprint2.\n",
        "\n",
        "- Predict the cuisines based on the images.\n",
        "\n",
        "- AI that draws images of the restaurant.\n",
        "\n",
        "- Detect anbormalities in the images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOe1aniTa64p"
      },
      "source": [
        "# Task 1: Predicting cuisines based on images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhNJSlvb1uwQ"
      },
      "source": [
        "## Task 1.1 Loading images for new deep learning\n",
        "\n",
        "---\n",
        "\n",
        "Because we are using deep learning, we can include more information. Therefore we don't need to use the HOG-values from sprint 2 anymore.\n",
        "\n",
        "We'll use the RGB values of the images and label them with the cuisine of the restaurant.\n",
        "\n",
        "At first, we'll only use the first cuisine of the restaurant. Later we'll try to use multi-label classification where the same image has multiple cuisines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGlpX0A8pMuJ"
      },
      "source": [
        "### Task 1.1.1 Setting up the labels.\n",
        "---\n",
        "\n",
        "Right now, we're using the first cuisine of the list for the restaurants, disregarding the others. </br>\n",
        "For further clean-up we've dropped the rows where the cuisine was NaN.\n",
        "\n",
        "For the machine, it's easier to understand numbers then text, so we've replaced the text with numerical values.\n",
        "\n",
        "First we would use a labelencoder, but the model could misunderstand the data. To prevent this we used a one-hot-encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "JKkUsx8M2CtZ",
        "outputId": "a39ad870-bf92-4f6a-b7a8-ca9af3a9d260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        0    1    2    3    4    5    6    7    8    9  ...   40   41   42  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "5549  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
              "5550  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
              "5551  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
              "5552  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
              "5553  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
              "\n",
              "       43   44   45   46   47   48  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "...   ...  ...  ...  ...  ...  ...   \n",
              "5549  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5550  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5551  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5552  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5553  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "                                                   path  \n",
              "0     /content/drive/MyDrive/MachineLearning/images/...  \n",
              "1     /content/drive/MyDrive/MachineLearning/images/...  \n",
              "2     /content/drive/MyDrive/MachineLearning/images/...  \n",
              "3     /content/drive/MyDrive/MachineLearning/images/...  \n",
              "4     /content/drive/MyDrive/MachineLearning/images/...  \n",
              "...                                                 ...  \n",
              "5549  /content/drive/MyDrive/MachineLearning/images/...  \n",
              "5550  /content/drive/MyDrive/MachineLearning/images/...  \n",
              "5551  /content/drive/MyDrive/MachineLearning/images/...  \n",
              "5552  /content/drive/MyDrive/MachineLearning/images/...  \n",
              "5553  /content/drive/MyDrive/MachineLearning/images/...  \n",
              "\n",
              "[5554 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc299b53-625b-4a2e-bfdc-c0d725ba7669\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5549</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5550</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5551</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5552</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5553</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5554 rows Ã— 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc299b53-625b-4a2e-bfdc-c0d725ba7669')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc299b53-625b-4a2e-bfdc-c0d725ba7669 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc299b53-625b-4a2e-bfdc-c0d725ba7669');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "path_images = glob.glob(\"/content/drive/MyDrive/MachineLearning/images/*.jpg\")\n",
        "\n",
        "afbeeldingen_df = pd.DataFrame(path_images, columns=[\"path\"])\n",
        "afbeeldingen_df[\"bestandsnaam\"] = afbeeldingen_df[\"path\"].apply(os.path.basename)\n",
        "afbeeldingen_df[\"restaurant_id\"] = afbeeldingen_df[\"bestandsnaam\"].str.split(\"_\",expand=True)[0]\n",
        "afbeeldingen_df['restaurant_id'] = afbeeldingen_df['restaurant_id'].astype(int)\n",
        "\n",
        "afbeeldingen_df = pd.merge(afbeeldingen_df, restaurant_df, left_on=\"restaurant_id\", right_on=\"id\", how=\"inner\")\n",
        "\n",
        "afbeeldingen_df['cuisines'] = afbeeldingen_df['cuisines'].str.split(',').str[:1]\n",
        "afbeeldingen_df['cuisines'] = afbeeldingen_df['cuisines'].str[0]\n",
        "\n",
        "afbeeldingen_df.dropna(subset=['cuisines'], inplace=True)\n",
        "afbeeldingen_df.reset_index(inplace=True)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y = afbeeldingen_df['cuisines'].values\n",
        "y = enc.fit_transform(y.reshape(-1,1))\n",
        "y_df = pd.DataFrame(y.toarray())\n",
        "\n",
        "data_hot = y_df\n",
        "data_hot['path'] = afbeeldingen_df['path']\n",
        "data_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tC7BS8TYbTx"
      },
      "source": [
        "The table now contains the path to the image and the rest of the columns are the hot_encoded values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtTj6MZzdz1v"
      },
      "source": [
        "### Task 1.1.2 Setting up images\n",
        "---\n",
        "\n",
        "Because the images have different sizes, we'll resize them all to (224,224,3).\n",
        "\n",
        "  -> Images will have height and width 224.\n",
        "\n",
        "  -> The 3rd dimension with size 3 is for the RGB-values.\n",
        "\n",
        "In sprint 2, we saw that a lot of images where black. These images aren't useful for the classification, so we opted to remove them. Also, images containing only a single color were removed.\n",
        "- We did this by using the grayscale of the image and calculating the amount of zeros.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9L4ZzGRJypt"
      },
      "outputs": [],
      "source": [
        "images_df = []\n",
        "label_df = []\n",
        "\n",
        "# Iterate over the rows of the dataframe\n",
        "for index, row in data_hot.iterrows():\n",
        "  # Make sure the 'path' column exists and is not empty\n",
        "  if 'path' in row and row['path']:\n",
        "    # Try to read the image and process it\n",
        "    try:\n",
        "      img = cv2.imread(row['path'])\n",
        "      gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      if cv2.countNonZero(gray_image) != 0 and cv2.countNonZero(gray_image) != gray_image.size:\n",
        "        # Remove all one color images\n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        if img.shape[2] == 1:\n",
        "          img = np.dstack([img, img, img])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32)/255.0\n",
        "        images_df.append(img)\n",
        "        label_df.append(row.iloc[:49])\n",
        "    except Exception as e:\n",
        "      # Print the error message if there is an error reading the image\n",
        "      print(f\"Error reading image at index {index}: {e}\")\n",
        "  else:\n",
        "    # Print a message if the 'path' column is missing or empty\n",
        "    print(f\"Missing or empty 'path' column at index {index}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHyUGZQV7xUe"
      },
      "source": [
        "### Task 1.1.2.1 Deleting duplicate images\n",
        "\n",
        "When detecting abnormals in the data. (Task 2) we saw that there were a lot of duplicate images. (stock pictures?).\n",
        "\n",
        "The same images had different labels, that leads to the model having to deal with contradictions, making the training noticeably harder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "giPbcYFEtv_v"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate images from the dataframe\n",
        "df = pd.DataFrame()\n",
        "df['image'] = images_df\n",
        "df['label'] = label_df\n",
        "\n",
        "# Create a function to check if an image is a duplicate\n",
        "def is_duplicate(row):\n",
        "    image = row['image']\n",
        "    # Check if the image is a duplicate\n",
        "    return any(np.all(image == x) for x in df['image'].values[:row.name])\n",
        "\n",
        "# Use the apply method to apply the function to each row of the dataframe\n",
        "df['duplicate'] = df.apply(is_duplicate, axis=1)\n",
        "\n",
        "# Remove duplicate images from the dataframe\n",
        "df = df.drop(df[df['duplicate'] == True].index)\n",
        "\n",
        "images_df = df['image'].values.tolist()\n",
        "label_df = pd.DataFrame(df['label'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIpXT0JQFDqR"
      },
      "source": [
        "## Task 1.2 Preparing the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knZlqHd8zsuV"
      },
      "source": [
        "### Task 1.2.1 Calculate the amount of output classes\n",
        "\n",
        "For classification, the last layer of the neural network needs the same amount of outputs as there are possiblie classes. Herefor, we calculate all possible classes. These are all the unique cuisines in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDbTqeRVzsfX",
        "outputId": "8ebfe6db-95cd-4972-957a-4d3806139e98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "amountOfClasses = afbeeldingen_df['cuisines'].unique().size\n",
        "amountOfClasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzRdgbWIZZjy"
      },
      "source": [
        "### Task 1.2.2 Split the data in test and training\n",
        "\n",
        "Because we have a small amount of data, we take a bigger part of it for training. 90% for training and 10% for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIkokcXMKD-q"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images_df, label_df, test_size=0.1) # 90% training and 10% test\n",
        "\n",
        "#y_train = to_categorical(y_train, amountOfClasses)\n",
        "#y_test = to_categorical(y_test, amountOfClasses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ltOlFrhJ4mF"
      },
      "source": [
        "### Task 1.2.3 Setting up the CNN Image Classification model\n",
        "---\n",
        "\n",
        "We want to do image classification, to achieve this goal we'll use a convolutional neural network.\n",
        "\n",
        "The model will be a linear stack of layers.\n",
        "\n",
        "- We start with a convolutional layer with 32 filters and a kernel size of 3 by 3.\n",
        "The input shape are the images.\n",
        "This layer is responsible for extracting features from the input image.\n",
        "We start with a lower filter size for the first convolutional layer and increase the size as we go deeper into the network. In a Convolutional Neural Network, the filters in the deeper layers are able to capture more complex features of an image because they are able to combine the features learned by the filters in the earlier layers. When you increase the number of filters in the deeper layers, it allows the network to learn more complex and higher-level features of the image, which can be more useful for image classification tasks.\n",
        "\n",
        "- We add an activation layer to it. We use ReLU as the activation function, with the purpose of introducing non-linearity into the model. ReLU is a common choice as activation function, as it is efficient and could allow the model to converge faster opposed to some other activation functions.\n",
        "\n",
        "- Next we want to downsample the output of the convolution layer. The pool size of (2,2) is used to downsample the input by a factor of 2 in both dimensions, which reduces the spatial dimensions of the output and allows the network to focus on the most important features.\n",
        "\n",
        "- We repeat this pattern, an increase of filters (32 to 64)  will increase the number of parameters in the model, which can allow the model to learn more complex features of the input data. At each pattern we added a dropout, to prevent overfitting. By randomly setting a fraction of the activations in the model to zero during training. the model is forced to learn more from the remaining parameters.\n",
        "\n",
        "- In the end we flatten the output, so our 3D feature map results in 1D feature vectors.\n",
        "\n",
        "- For the output we use 2 connected dense layers, where the last dense has the same amount of output nodes as there are labels/classes.\n",
        "\n",
        "- For the last activation-layer was use softmax, a common used activation layer for a cCassification Neural Network. Softmax converts the output of the final layer of the network, which is a set of raw prediction scores, into a probability distribution over the classes. This makes it possible for the network to distribute the probabilities of the different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-WakI8yMDn6"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), input_shape=(224,224,3))) #Eerste layer,\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten()) # Converting 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(amountOfClasses)) #Amount of outputs\n",
        "model.add(Activation('softmax')) #For multi classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0Rtkb3AKIy9"
      },
      "source": [
        "### Task 1.2.4 Compile the model\n",
        "---\n",
        "\n",
        "#### Learning rate and momentum\n",
        "The model will start with a learning rate of 0.01 and momentum of 0.7.\n",
        "\n",
        "-> When stuck in a local minimum, we increased the momentum, by 0.1.\n",
        "\n",
        "-> Over time we increased the learning rate, for faster modeling and testing if there are some improvements.\n",
        "\n",
        "\n",
        "We start with a higher momentum, to get to the global minima faster and attemting to escape local minima.\n",
        "\n",
        "We do however take the risk of going past the global minima by using a higher momentum.\n",
        "\n",
        "\n",
        "For the learning rate we use a small value, so that the optimizer takes small steps when updating the model's weights. The network will train slower, but also more accurately to the global minimum.\n",
        "\n",
        "#### Lossfunction and optimizer\n",
        "\n",
        "For the loss function we choose the most common one, within Tensorflow for multi-classification: categorical_crossentropy.\n",
        "\n",
        "For the optimizer we started with using SGD, because:\n",
        "  - It's easy to use/implement\n",
        "  - It only needs to compute the gradient of the loss function, but not for the whole dataset, but for a single or small batch of datapoints.\n",
        "  - SGD is capable of dealing with high-dimensional datasets, which is useful when working with images.\n",
        "  - SGD should be better at escaping local minima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIUiKqQBKGto",
        "outputId": "bddd7f63-c8c3-4a23-f064-5bb99a957e3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# compile model\n",
        "opt = SGD(lr=0.05, momentum=1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGjiHGhKRaN"
      },
      "source": [
        "## Task 1.3 Fitting model\n",
        "\n",
        "We increased the batch_size for better results. The downsite to this, is that it will take more time for the neural network to train.\n",
        "\n",
        "A smaller batch size can lead to faster training, but can also result in higher variance in the model's performance. To prevent the higher variance, we started with a higher amount of samples to use.\n",
        "\n",
        "We used the most common batch size: 32,64 and 128. Starting with 32 and increasing to 128.\n",
        "\n",
        "The number of epochs starts at 100 and will be increased to see if there are better results. The model with go over the dataset 100 times.\n",
        "-  that means: (6094/32) * 100 batches during the training.\n",
        "  - Depending on the batch size, the amount of batches will be less."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euXBH-6CKLLc",
        "outputId": "e6145042-0ff8-4e85-dfab-374623d8aae0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-53-80a9b062cf29>:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y=np.array(y_train, dtype=np.float),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - 15s 58ms/step - loss: 6.4557 - accuracy: 0.3193\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 5s 53ms/step - loss: 3.1138 - accuracy: 0.3513\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.1201 - accuracy: 0.3865\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.0791 - accuracy: 0.2642\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.1854 - accuracy: 0.3928\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.2183 - accuracy: 0.3846\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.0694 - accuracy: 0.3582\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.3566 - accuracy: 0.3503\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.3325 - accuracy: 0.3727\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 5s 54ms/step - loss: 3.3278 - accuracy: 0.4037\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0db81343a0>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32 #Number of samples before updating the network\n",
        "nb_epochs = 10 #Epoch = aantal keer dat het algoritme over de training dataset gaat.\n",
        "\n",
        "#model.fit(x=np.array(X_train),\n",
        "#          y=np.array(y_train, dtype=np.float))\n",
        "#X_train = tf.convert_to_tensor(X_train)\n",
        "\n",
        "model.fit(x=np.array(X_train),\n",
        "          y=np.array(y_train, dtype=np.float),\n",
        "          batch_size=batch_size,\n",
        "          epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HVrQRodRO7y",
        "outputId": "878c0bf4-1e97-4923-b941-9de6a8bbc38e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-54-792df1b3fd92>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=batch_size)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 1s 43ms/step - loss: 3.2365 - accuracy: 0.4837\n",
            "Loss: 3.2364821434020996 accuracy:  0.48367953300476074\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=batch_size)\n",
        "print('Loss:', loss, 'accuracy: ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbDixjjS78D9"
      },
      "source": [
        "## Task 1.4 Evaluate model:\n",
        "\n",
        "In the model above, we can assume that the model is stuck in a local minimum.\n",
        "\n",
        "We tried to train with different the learning rates and momentums, but without success. Even by playing with the batches and the amount of epochs, we couldn't increase the performance of the model.\n",
        "\n",
        "That the test-data had a higher score then the trainingsdata, could indicate that the distribution of the data isn't suited for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX_iotCTD5gM"
      },
      "source": [
        "## Task 1.5 Improve the results\n",
        "\n",
        "It is quite evident that our validation accuracy is not that good. There are a number of tricks that we can use to improve the performance of the model.\n",
        "\n",
        "- Adding more layers to the model. This can help the model learn more complex features from the input data, allowing it to make more accurate predictions.\n",
        "\n",
        "- A larger dataset can provide the model with more examples to learn from, which can help it generalize better to unseen data.\n",
        "  \n",
        "  -> (-) We don't have more data.\n",
        "\n",
        "- Using data augmentation: This can help the model generalize better to unseen data by providing it with more diverse examples to learn from.\n",
        "  - Check the distribution of the data. Increase the amount of datapoints, which are less present in the dataset. This seems a promising and achievable solution for our problem.\n",
        "  \n",
        "- Use a different optimizer. Using a different optimizer, such as Adam or RMSprop, can potentially improve the model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF5I9rndjiNI"
      },
      "source": [
        "## Task 1.6 Discuss distribution of the data\n",
        "\n",
        "=> In the dataset the duplicates are already removed. </br>\n",
        "</br>\n",
        "\n",
        "We see that the data has unbalanced classes. This can lead to problems such as:\n",
        "- High chance that our test-data wouldn't representive for the trainingdata.\n",
        "\n",
        "A large amount of rows are labeled as 'Belgian', this label occurs 5x more frequently than the value with the second highest frequency.\n",
        "  - We need to fix the unbalanced classes before we can train the model.\n",
        "\n",
        "\n",
        "Options for unbalanced data:\n",
        "  - Under-sampling: here, samples of the majority class will be removed. Because of the lack of data, this isn't hulpful for us.\n",
        "\n",
        "  - Over-sampling: here samples of the minority class will be duplicated\n",
        "  - Data augmenation: inserting new samples based on existing samples. But they are slightly different.\n",
        "    - This will affect the balance of the dataset.\n",
        "  - Instead of taking the first cuisine, we can pick a random cuisines correlated to the restaurant.\n",
        "\n",
        "<br/>\n",
        "\n",
        "=> We opted for **data augmentation**\n",
        "\n",
        "Reasons for the unbalanced data (by gut feeling) :\n",
        "  - We take the first cuisine that is listed in the datarow. Further in the notebook we'll try multi-label classification, where we won't have this problem.\n",
        "  - The dataset is for Belgian restaurants, so it isn't the weird that the majority of the cuisines are labeled as 'Belgian'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTiH_jbaVVif",
        "outputId": "25c0d55c-4ab1-40c5-9232-010c3159ac01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_encoders.py:582: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
            "  X = check_array(X, accept_sparse=\"csr\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([['Belgian'],\n",
              "       ['Belgian'],\n",
              "       ['Belgian'],\n",
              "       ...,\n",
              "       ['Steakhouse'],\n",
              "       ['Steakhouse'],\n",
              "       ['Steakhouse']], dtype=object)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories_decoded = enc.inverse_transform(label_df)\n",
        "categories_decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpjnwm6IdRDy",
        "outputId": "3ddaeca0-5caa-429e-8f2c-6610e86a7674"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Belgian             1517\n",
              "Italian              508\n",
              "French               391\n",
              "European             188\n",
              "Bar                  187\n",
              "Chinese              153\n",
              "Cafe                 112\n",
              "Japanese             108\n",
              "International         93\n",
              "Pizza                 87\n",
              "American              81\n",
              "Turkish               78\n",
              "Spanish               64\n",
              "Contemporary          63\n",
              "Seafood               49\n",
              "Sushi                 48\n",
              "Pub                   47\n",
              "Asian                 45\n",
              "Dutch                 44\n",
              "Thai                  43\n",
              "Mediterranean         42\n",
              "Grill                 40\n",
              "Fast Food             40\n",
              "Mexican               38\n",
              "Moroccan              29\n",
              "Indian                28\n",
              "Healthy               26\n",
              "Greek                 21\n",
              "Brazilian             19\n",
              "Barbecue              19\n",
              "Steakhouse            16\n",
              "Lebanese              15\n",
              "African               13\n",
              "Brew Pub              12\n",
              "Persian                8\n",
              "Diner                  7\n",
              "Deli                   7\n",
              "Gastropub              7\n",
              "Middle Eastern         6\n",
              "Irish                  6\n",
              "Street Food            5\n",
              "Wine Bar               5\n",
              "Fusion                 5\n",
              "German                 4\n",
              "Polish                 4\n",
              "Beer restaurants       3\n",
              "Peruvian               2\n",
              "Tunisian               2\n",
              "Name: values, dtype: int64"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(categories_decoded, columns=['values'])\n",
        "counts = df['values'].value_counts()\n",
        "\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "fzBD9pvrNwMg",
        "outputId": "57c9d8fd-6762-419e-c7ef-2b056bcbaecc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Belgian'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plt.bar(counts.index, counts.values)\n",
        "plt.xlabel('Cuisines')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of the cuisines')\n",
        "plt.show()\n",
        "\n",
        "counts.index[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jna8gGK3dXPe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIuzJ3oFNubO"
      },
      "source": [
        "### Task 1.6.1 Fixing the unbalanced cuisines.\n",
        "---\n",
        "\n",
        "Option 1: data augmentation\n",
        "-> but we only need to do data augmentation for specific classes.\n",
        "\n",
        "\n",
        "Option 2: Oversampling: duplicate the data from the unbalanced part. </br>\n",
        "-> Would this result in a dataset accurately representing reality? </br>\n",
        "-> Rare cuisines with 1 image could get easily overfitted </br>\n",
        "\n",
        "\n",
        "Option 3: Remove the cuisines with 'Belgian' only when this is the only label given.\n",
        "\n",
        "\n",
        "option 4: Undersampling\n",
        "  - Here, we'll balance the class distribution of the cuisines by reducing the size of the over-represented class 'Belgian'.\n",
        "\n",
        "\n",
        "</br>\n",
        "=> In the beginning we went for the first option, because it also helps with the lack of data. But it uses to much RAM, so the notebook keeps crashing. Herefor we wrote our own data augmentation script, instead of the built-in libraries.\n",
        "</br>\n",
        "\n",
        "Later we combined the augmented data with option 4.\n",
        "Here we used **RandomUnderSampler** for undersampling the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vqqPv3tf2Dg"
      },
      "source": [
        "#### Task 1.6.1.1 Data augmentation\n",
        "\n",
        "Every randomized attribute has a 50% chance of being used over the image.\n",
        "This makes it possible that some images are just duplicated, but that's fine.\n",
        "\n",
        "We'll ignore the images that are labed 'Belgian', because we have enough of those. We need more samples of the other cuisines.\n",
        "\n",
        "First we tried using the built-in library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF1vf4dg7_fR",
        "outputId": "24abdcfd-e267-4173-aaee-be39de1d02e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_df[0][6] #Labeled as Belgian"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hM3upUBjxvz"
      },
      "source": [
        "#### Task 1.6.1.2 Own version of data augmentation\n",
        "\n",
        "Google collab keeps crashing and can't handle the process for data augmentation. </br>\n",
        "\n",
        "As a result we aren't using the built-in data augmentation libraries, because these keep crashing and are asking for too much ram. We wrote our own version for data augmentation.\n",
        "\n",
        "```python\n",
        "  if random.randint(0,9) < 5:\n",
        "    flipped_img = cv2.flip(img, 1) #Flip it horizontal\n",
        "    images_df.append(flipped_img)\n",
        "    label_df.append(row.iloc[:49])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKetsozzu0dW"
      },
      "outputs": [],
      "source": [
        "images_df = []\n",
        "label_df = []\n",
        "\n",
        "# Iterate over the rows of the dataframe\n",
        "for index, row in data_hot.iterrows():\n",
        "  # Make sure the 'path' column exists and is not empty\n",
        "  if 'path' in row and row['path']:\n",
        "    # Try to read the image and process it\n",
        "    try:\n",
        "      img = cv2.imread(row['path'])\n",
        "      gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      if cv2.countNonZero(gray_image) != 0 and cv2.countNonZero(gray_image) != gray_image.size:\n",
        "        # Remove all one color images\n",
        "        img = cv2.resize(img, (224, 224))\n",
        "        if img.shape[2] == 1:\n",
        "          img = np.dstack([img, img, img])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = img.astype(np.float32)/255.0\n",
        "\n",
        "        if row[6] != 1.0: #Filter belgian\n",
        "            if random.randint(0,9) < 5:\n",
        "              flipped_img = cv2.flip(img, 1) #Flip it horizontal\n",
        "              images_df.append(flipped_img)\n",
        "              label_df.append(row.iloc[:49])\n",
        "\n",
        "        images_df.append(img)\n",
        "        label_df.append(row.iloc[:49])\n",
        "    except Exception as e:\n",
        "      # Print the error message if there is an error reading the image\n",
        "      print(f\"Error reading image at index {index}: {e}\")\n",
        "  else:\n",
        "    # Print a message if the 'path' column is missing or empty\n",
        "    print(f\"Missing or empty 'path' column at index {index}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BdJcfYAQ-qS"
      },
      "source": [
        "Removing duplicate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYoc8XU7-qUc"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate images from the dataframe\n",
        "df = pd.DataFrame()\n",
        "df['image'] = images_df\n",
        "df['label'] = label_df\n",
        "\n",
        "# Create a function to check if an image is a duplicate\n",
        "def is_duplicate(row):\n",
        "    image = row['image']\n",
        "    # Check if the image is a duplicate\n",
        "    return any(np.all(image == x) for x in df['image'].values[:row.name])\n",
        "\n",
        "# Use the apply method to apply the function to each row of the dataframe\n",
        "df['duplicate'] = df.apply(is_duplicate, axis=1)\n",
        "\n",
        "# Remove duplicate images from the dataframe\n",
        "df = df.drop(df[df['duplicate'] == True].index)\n",
        "\n",
        "images_df = df['image'].values.tolist()\n",
        "label_df = pd.DataFrame(df['label'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_aCJ5j53-qk"
      },
      "source": [
        "#### Task 1.6.1.3 Check new distribution\n",
        "\n",
        "The dataset is still unbalanced, we can fix this by applying some undersampling on rows labeled as 'Belgian'.\n",
        "\n",
        "(â€“) The new dataset should be a good representive of the original dataset.</br> We need to be keep this in mind when we are training the model with this dataset. </br>\n",
        "(â€“) First we do some augmentation for adding more samples and now we are reducing the amount of samples. </br> That's not ideal, but because the rows aren't related to each other, it shouldn't harm the data that much."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vyUybkcxoyX"
      },
      "outputs": [],
      "source": [
        "categories_decoded = enc.inverse_transform(label_df)\n",
        "#categories_decoded\n",
        "\n",
        "df = pd.DataFrame(categories_decoded, columns=['values'])\n",
        "counts = df['values'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "YJycjROzxrMg",
        "outputId": "106a603a-ee96-45c5-c14a-746619861872"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Belgian'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plt.bar(counts.index, counts.values)\n",
        "plt.xlabel('Cuisines')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of the cuisines')\n",
        "plt.show()\n",
        "\n",
        "counts.index[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzAdFDVAEB23"
      },
      "source": [
        "#### Task 1.6.1.4 Undersampling the data.\n",
        "\n",
        "The data is still unbalanced, we are going to undersample the label 'Belgian'. </br> For this, we'll use RandomUnderSampler. </br>\n",
        "\n",
        "RandomUnderSampler is easy to implement and is straightforward.\n",
        "\n",
        "It randomly selects a subset of the majority class samples to remove from the dataset, until the class balance is restored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaCfXVjxDgA4",
        "outputId": "0a0c1018-15aa-45da-ac42-84c508e28e61"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-cbbc50c6bc98>:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  features = np.array(images_df, dtype=np.int)\n",
            "<ipython-input-7-cbbc50c6bc98>:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  labels = np.array(label_df, dtype=np.float)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Flatten the images into a single feature vector\n",
        "features = np.array(images_df, dtype=np.int)\n",
        "features = features.reshape(features.shape[0], -1)\n",
        "\n",
        "labels = np.array(label_df, dtype=np.float)\n",
        "\n",
        "# Create a RandomUnderSampler object\n",
        "rus = RandomUnderSampler()\n",
        "\n",
        "# Use the fit_resample method to undersample the dataset\n",
        "X_resampled, y_resampled = rus.fit_resample(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPvp0X63pJHQ"
      },
      "outputs": [],
      "source": [
        "X_resampled = X_resampled.reshape(X_resampled.shape[0], 224, 224, 3)\n",
        "y_resampled = pd.DataFrame(y_resampled)\n",
        "y_resampled[48] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcnQEXE18Ame",
        "outputId": "548e80cd-488d-423d-86a8-8c757941f884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape labels: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(48, 224, 224, 3)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Shape images: \")\n",
        "X_resampled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOXjXXen8QBt",
        "outputId": "339e35a7-e481-43ed-b85d-9e1b708793bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape images: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(48, 49)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Shape labels: \")\n",
        "y_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzNvtagansvN"
      },
      "source": [
        "#### Disappointed\n",
        "\n",
        "The undersampling is too extreme. We have a condensation that's too big. As a result, the training dataset might be too small to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2fOKIRQ79My"
      },
      "source": [
        "#### Task 1.6.1.5 Check new distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Bus9xE-5oryg",
        "outputId": "e96cbfda-6811-4c61-e8df-374592ba0c20"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'African'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categories_decoded = enc.inverse_transform(y_resampled)\n",
        "#categories_decoded\n",
        "\n",
        "df = pd.DataFrame(categories_decoded, columns=['values'])\n",
        "counts = df['values'].value_counts()\n",
        "\n",
        "plt.bar(counts.index, counts.values)\n",
        "plt.xlabel('Cuisines')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of the cuisines')\n",
        "plt.show()\n",
        "\n",
        "counts.index[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8dtGXVu7Ihe"
      },
      "source": [
        "##### Task 1.6.1.6 Check amount of datapoints\n",
        "\n",
        "The distribution of the different cuisines is now balanced. But the amount of datapoints is very low and not useful for training the model. </br>\n",
        "\n",
        "Taking the previous into consideration, we decided to not fit this data in the model. We'll only test the augmentated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgqcKb4fhpH2"
      },
      "source": [
        "### Task 1.6.2 Fitting network with augmentated data\n",
        "\n",
        "We'll use the last model and fit it again.\n",
        "\n",
        "The batch_size will be smaller, because the amount of data is way smaller."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXk-vTFZiOou"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images_df, label_df, test_size=0.1) # 90% training and 10% test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smuGEfOiiDO4",
        "outputId": "4b9d86e4-4b4b-43dd-8406-09e1bafc042e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-8e2f9d4d4b7e>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y=np.array(y_train, dtype=np.float),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "121/121 [==============================] - 16s 56ms/step - loss: 3.1959 - accuracy: 0.2913\n",
            "Epoch 2/10\n",
            "121/121 [==============================] - 7s 54ms/step - loss: 6.7583 - accuracy: 0.1914\n",
            "Epoch 3/10\n",
            "121/121 [==============================] - 6s 54ms/step - loss: 446.6925 - accuracy: 0.1632\n",
            "Epoch 4/10\n",
            "121/121 [==============================] - 7s 54ms/step - loss: 8.1652 - accuracy: 0.1743\n",
            "Epoch 5/10\n",
            "121/121 [==============================] - 7s 54ms/step - loss: 7.6021 - accuracy: 0.2381\n",
            "Epoch 6/10\n",
            "121/121 [==============================] - 7s 57ms/step - loss: 9.0674 - accuracy: 0.2135\n",
            "Epoch 7/10\n",
            "121/121 [==============================] - 6s 54ms/step - loss: 9.3937 - accuracy: 0.2288\n",
            "Epoch 8/10\n",
            "121/121 [==============================] - 7s 54ms/step - loss: 7.5302 - accuracy: 0.2067\n",
            "Epoch 9/10\n",
            "121/121 [==============================] - 6s 54ms/step - loss: 8.0634 - accuracy: 0.1831\n",
            "Epoch 10/10\n",
            "121/121 [==============================] - 6s 53ms/step - loss: 9.3148 - accuracy: 0.2495\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c7596acd0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32 #Number of samples before updating the network\n",
        "nb_epochs = 10 #Epoch = aantal keer dat het algoritme over de training dataset gaat.\n",
        "\n",
        "model.fit(x=np.array(X_train),\n",
        "          y=np.array(y_train, dtype=np.float),\n",
        "          batch_size=batch_size,\n",
        "          epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAtxqSU_jQx-",
        "outputId": "866f5c75-9524-4ef7-c3be-aca3fa5eb2d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-792df1b3fd92>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=batch_size)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 37ms/step - loss: 9.2154 - accuracy: 0.1072\n",
            "Loss: 9.215397834777832 accuracy:  0.10722610354423523\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=batch_size)\n",
        "print('Loss:', loss, 'accuracy: ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg3i3Lyi861A"
      },
      "source": [
        "### Task 1.6.3 Evaluate model with augmentated data\n",
        "\n",
        "There isn't a big improvement in the performance of the model. The influence of the distribution didn't have a big impact on the performance. </br> The data itself may be not useful for the given task.\n",
        "\n",
        "- Other reasons for the even worse results is the used data-augmentation. We could have choose a data augmentation technique that suided better for our data.\n",
        "\n",
        "- Because we used data-augemntation on the underbalanced data, the model could have learned incorrect patterns.\n",
        "\n",
        "We could work with a different approach to the dataset. By not taking the first cuisines for each image, but a random cuisine that was assigned to the image. </br> Here, the performance of the model would depend on the training dataset.\n",
        "If you want to compare different models, the dataset will also be different.\n",
        "\n",
        "-> Another possibility would be to readjust the neural network, because of the deadlines we didn't go that road."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9cUjrKXYppv"
      },
      "source": [
        "## Task 1.7 Try the model with a different optimizer\n",
        "\n",
        "This will be trained with the original dataset. (Not the augmentated dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcD6vBhurYEV",
        "outputId": "ea835228-b45b-45be-ac7c-18618a0a8380"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-5f9eda4e90b1>:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y=np.array(y_train, dtype=np.float),\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - 257s 3s/step - loss: 3.0708 - accuracy: 0.4413\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 250s 3s/step - loss: 2.4788 - accuracy: 0.4449\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 250s 3s/step - loss: 2.4399 - accuracy: 0.4449\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 259s 3s/step - loss: 2.4157 - accuracy: 0.4443\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 254s 3s/step - loss: 2.3769 - accuracy: 0.4443\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 250s 3s/step - loss: 2.2907 - accuracy: 0.4515\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 251s 3s/step - loss: 2.1383 - accuracy: 0.4634\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 251s 3s/step - loss: 1.9263 - accuracy: 0.4944\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 250s 3s/step - loss: 1.7147 - accuracy: 0.5317\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 251s 3s/step - loss: 1.4434 - accuracy: 0.5894\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46e99d3d00>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 32 #In hoeveel gaan we de data splitten.\n",
        "nb_epochs = 10 #Epoch = aantal keer dat het algoritme over de training dataset gaat, voor dat de parameters aan gepast worden.\n",
        "\n",
        "model.fit(x=np.array(X_train),\n",
        "          y=np.array(y_train, dtype=np.float),\n",
        "          batch_size=batch_size,\n",
        "          epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKVAHNu7ZEMg",
        "outputId": "30a45d39-301e-4c9b-aac0-53a9afe407d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-98045edec227>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85/85 [==============================] - 8s 93ms/step - loss: 2.9825 - accuracy: 0.3086\n",
            "Loss: 2.982518196105957 accuracy:  0.3086053431034088\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=4)\n",
        "print('Loss:', loss, 'accuracy: ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrJ9vyyEjPav"
      },
      "source": [
        "The trainingsdata scores better, I think with a bigger amount of trainingsdata, this model would score and train better, without the use of data-augmentation.\n",
        "\n",
        "But the distribution of the data still has a big impact on the performance of the model.\n",
        "\n",
        "Tweaking the model more and trying different loss functions and optimizers would be an improvement for the model. </br> Nevertheless, this takes a lot of time, for getting these parameters right."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcWBA3VqfK2-"
      },
      "source": [
        "## Task 1.8 Multi-lable classification for cuisines\n",
        "\n",
        "For the multi-label classification, we use the same dataset, but with a different preprocessing. We don't use the first cuisine, but we include all the cuisines related to the restaurant. </br>\n",
        "\n",
        "For every image, we add a new row for each cuisine.\n",
        "\n",
        "```python\n",
        "afbeeldingen_Option3_df = afbeeldingen_Option3_df.explode('cuisines').reset_index(drop=True)\n",
        "```\n",
        "\n",
        "Later we use one-hot encoding over the cuisines.</br>\n",
        "Thanks to one-hot encoding, we can combine the different cuisines by grouping by image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "a25imntVfQWL",
        "outputId": "33a11c3b-1113-4641-fcd5-7cf214334f2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   path    0    1    2    3  \\\n",
              "0     /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "1     /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "2     /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "3     /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "4     /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "...                                                 ...  ...  ...  ...  ...   \n",
              "5549  /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "5550  /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "5551  /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "5552  /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "5553  /content/drive/MyDrive/MachineLearning/images/...  0.0  0.0  0.0  0.0   \n",
              "\n",
              "        4    5    6    7    8  ...  110  111  112  113  114  115  116  117  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "5549  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5550  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5551  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5552  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "5553  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
              "\n",
              "      118  119  \n",
              "0     0.0  0.0  \n",
              "1     0.0  0.0  \n",
              "2     0.0  0.0  \n",
              "3     0.0  0.0  \n",
              "4     0.0  0.0  \n",
              "...   ...  ...  \n",
              "5549  0.0  0.0  \n",
              "5550  0.0  0.0  \n",
              "5551  0.0  0.0  \n",
              "5552  0.0  0.0  \n",
              "5553  0.0  0.0  \n",
              "\n",
              "[5554 rows x 121 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fc01cfa-c3d3-49af-b266-8e2f7b6dba2c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5549</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5550</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5551</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5552</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5553</th>\n",
              "      <td>/content/drive/MyDrive/MachineLearning/images/...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5554 rows Ã— 121 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fc01cfa-c3d3-49af-b266-8e2f7b6dba2c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7fc01cfa-c3d3-49af-b266-8e2f7b6dba2c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7fc01cfa-c3d3-49af-b266-8e2f7b6dba2c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "path_images = glob.glob(\"/content/drive/MyDrive/MachineLearning/images/*.jpg\")\n",
        "\n",
        "afbeeldingen_Option3_df = pd.DataFrame(path_images, columns=[\"path\"])\n",
        "afbeeldingen_Option3_df[\"bestandsnaam\"] = afbeeldingen_Option3_df[\"path\"].apply(os.path.basename)\n",
        "afbeeldingen_Option3_df[\"restaurant_id\"] = afbeeldingen_Option3_df[\"bestandsnaam\"].str.split(\"_\",expand=True)[0]\n",
        "afbeeldingen_Option3_df['restaurant_id'] = afbeeldingen_Option3_df['restaurant_id'].astype(int)\n",
        "\n",
        "afbeeldingen_Option3_df = pd.merge(afbeeldingen_Option3_df, restaurant_df, left_on=\"restaurant_id\", right_on=\"id\", how=\"inner\")\n",
        "\n",
        "afbeeldingen_Option3_df['cuisines'] = afbeeldingen_Option3_df['cuisines'].str.split(',')\n",
        "afbeeldingen_Option3_df = afbeeldingen_Option3_df.explode('cuisines').reset_index(drop=True)\n",
        "\n",
        "afbeeldingen_Option3_df.dropna(subset=['cuisines'], inplace=True)\n",
        "afbeeldingen_Option3_df.reset_index(inplace=True)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "y = afbeeldingen_Option3_df['cuisines'].values\n",
        "y = enc.fit_transform(y.reshape(-1,1))\n",
        "y_df = pd.DataFrame(y.toarray())\n",
        "\n",
        "data_hot_multi = y_df\n",
        "data_hot_multi['path'] = afbeeldingen_Option3_df['path']\n",
        "data_hot_multi\n",
        "\n",
        "data_hot_multi = data_hot_multi.groupby(\"path\").sum().reset_index()\n",
        "data_hot_multi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7kRCtywMMPM"
      },
      "source": [
        "### Task 1.8.1 Setting up the images\n",
        "\n",
        "Same as in Task 1.1.2. We filter the images that are black."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWvGUWLkMOiG"
      },
      "outputs": [],
      "source": [
        "images_df = []\n",
        "label_df = []\n",
        "\n",
        "for index, row in data_hot_multi.iterrows():\n",
        "#for img in path_images:\n",
        "  try:\n",
        "    #imgV2 = img\n",
        "    img = cv2.imread(str(row['path']))\n",
        "\n",
        "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    if cv2.countNonZero(gray_image) != 0 and cv2.countNonZero(gray_image) != gray_image.size:\n",
        "\n",
        "      img = cv2.resize(img, (224, 224))\n",
        "      if img.shape[2] == 1:\n",
        "          img = np.dstack([img, img, img])\n",
        "\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      img = img.astype(np.float32)/255.0\n",
        "      images_df.append(img)\n",
        "      label_df.append(row.iloc[-120:])\n",
        "\n",
        "  except:\n",
        "    print(\"Error: \", index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TIu-ddQRD0f"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate images from the dataframe\n",
        "df = pd.DataFrame()\n",
        "df['image'] = images_df\n",
        "df['label'] = label_df\n",
        "\n",
        "# Create a function to check if an image is a duplicate\n",
        "def is_duplicate(row):\n",
        "    image = row['image']\n",
        "    # Check if the image is a duplicate\n",
        "    return any(np.all(image == x) for x in df['image'].values[:row.name])\n",
        "\n",
        "# Use the apply method to apply the function to each row of the dataframe\n",
        "df['duplicate'] = df.apply(is_duplicate, axis=1)\n",
        "\n",
        "# Remove duplicate images from the dataframe\n",
        "df = df.drop(df[df['duplicate'] == True].index)\n",
        "\n",
        "images_df = df['image'].values.tolist()\n",
        "label_df = pd.DataFrame(df['label'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8zEQfH3bvyW"
      },
      "source": [
        "### Task 1.8.2 Preparation of the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OUqClquOuT_"
      },
      "source": [
        "#### Task 1.8.2.1 Calculate the amount of outputs classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2ocW5U5Litt",
        "outputId": "4f7a07cb-74a7-4d24-ea81-19f1cd0acf63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "amountOfClasses = afbeeldingen_Option3_df['cuisines'].unique().size\n",
        "amountOfClasses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qquOdGjBOrFN"
      },
      "source": [
        "#### Task 1.8.2.2 Splitting in test and trainingsdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoAYc9FuMG3M"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(images_df, label_df, test_size=0.1) # 90% training and 10% test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSHJseZOnzs"
      },
      "source": [
        "#### Task 1.8.2.3 Setting up the model\n",
        "\n",
        "\n",
        "It's the same neural network as for multi-classification. The only difference is in the last layer, where we use sigmoid as activation function.\n",
        "\n",
        "We use the sigmoid activation function, because it's commonly used in the output layer of a neural network for multi-label classification. This is because the sigmoid function maps any input value to a value between 0 and 1, which can be interpreted as a probability."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(X_train).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yl2fHNtQvD1",
        "outputId": "9779b8e4-d679-4450-de56-e902558a5f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3032, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOWaMERwOj8y"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3,3), input_shape=(224,224,3))) #Eerste layer,\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten()) # Converting 3D feature maps to 1D feature vectors\n",
        "\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(amountOfClasses)) #Amount of outputs\n",
        "model.add(Activation('sigmoid')) #For multi-label classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3ELyrONPCzc"
      },
      "source": [
        "#### Task 1.8.2.4 Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQhHSwynPBxl"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "#opt = SGD(lr=0.05, momentum=1)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huaoofe_PFXf"
      },
      "source": [
        "#### Task 1.8.2.5 Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arEYV_2xPH4L",
        "outputId": "a35ffcef-b4fe-48ac-c7c9-c0bd60466f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-8e2f9d4d4b7e>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y=np.array(y_train, dtype=np.float),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "95/95 [==============================] - 249s 3s/step - loss: 0.1775 - accuracy: 0.2302\n",
            "Epoch 2/10\n",
            "95/95 [==============================] - 244s 3s/step - loss: 0.0732 - accuracy: 0.3384\n",
            "Epoch 3/10\n",
            "95/95 [==============================] - 238s 3s/step - loss: 0.0723 - accuracy: 0.3407\n",
            "Epoch 4/10\n",
            "95/95 [==============================] - 242s 3s/step - loss: 0.0713 - accuracy: 0.3351\n",
            "Epoch 5/10\n",
            "95/95 [==============================] - 244s 3s/step - loss: 0.0711 - accuracy: 0.3371\n",
            "Epoch 6/10\n",
            "95/95 [==============================] - 237s 2s/step - loss: 0.0705 - accuracy: 0.3232\n",
            "Epoch 7/10\n",
            "95/95 [==============================] - 246s 3s/step - loss: 0.0697 - accuracy: 0.3054\n",
            "Epoch 8/10\n",
            "95/95 [==============================] - 251s 3s/step - loss: 0.0685 - accuracy: 0.3229\n",
            "Epoch 9/10\n",
            "95/95 [==============================] - 258s 3s/step - loss: 0.0671 - accuracy: 0.3150\n",
            "Epoch 10/10\n",
            "95/95 [==============================] - 257s 3s/step - loss: 0.0654 - accuracy: 0.3008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbce16f24c0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "batch_size = 32 #Number of samples before updating the network\n",
        "nb_epochs = 10 #Epoch = aantal keer dat het algoritme over de training dataset gaat.\n",
        "\n",
        "model.fit(x=np.array(X_train),\n",
        "          y=np.array(y_train, dtype=np.float),\n",
        "          batch_size=batch_size,\n",
        "          epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHXgSdql6DFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256c64b5-8bb5-43ea-9e23-d15ccfc43719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-98045edec227>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85/85 [==============================] - 9s 101ms/step - loss: 0.0973 - accuracy: 0.3056\n",
            "Loss: 0.09730713069438934 accuracy:  0.30563798546791077\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(np.array(X_test), np.array(y_test, dtype=np.float), batch_size=4)\n",
        "print('Loss:', loss, 'accuracy: ', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd1dsqkk_zqQ"
      },
      "source": [
        "### Task 1.8.2.6 Evaluate multi-label classification\n",
        "\n",
        "The amount of classes was way bigger then in the multi-classification (120 cuisines vs. 50 cuisines), so the task is harder. We can't make a fair comparison between the 2 models.\n",
        "\n",
        "Overall, the results of the multi-label classification were okay. Knowing that the model was trained with a small dataset. Multi-label classification is a more difficult task to perform.\n",
        "\n",
        "The model was also trained for a more realistic task, where a meal could belong to different cuisines, instead of just one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5MN0RJFcHEt"
      },
      "source": [
        "## Task 1.9 Evaluate different approaches for predicting the cuisines based on the pictue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM-xKQJweUCj"
      },
      "source": [
        "| Description | Pros | contras |\n",
        "|----------|----------|----------|\n",
        "| Classification without data augmentation   | (+) Easy to understand, was a good start. | (-) By the way of selecting the data a lot of cuisines where missing, 50 against 120. <br /> (-) We were stuck in a local minima, but it seems more likely that data wasn't right for the task. <br /> (-) We hadn't have mutch data available, that could be a reason for the underperformance of the neural network. <br /> (-) Data is not in balance, what results in not a good trainingset.|\n",
        "| Classification with data augmentation   | (+) More available datapoints, should have result in better performance <br /> (+) Data is more in balance, more trainingsdata to train with. | (-) Data augmentation is realy heavy to proces. <br /> (-) Still not working with all the cuisines. <br />|\n",
        "| Classification with data augmentation + undersampling  | (+) Less 'Belgian' label in the data. <br /> (+) Data is more in balance. | (-) Not the best representation of the data <br /> (-) Still not working with all the cuisines. <br /> (-) really small amount of trainingsdata.|\n",
        "| Multi-lable classification | (+) All the cuisines are included. <br /> (+) More features <br /> (+) More realistic approche, that a restaurant has multiple cuisines. | (-) Heavy for the computer to process. </br>|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrRSApIw-327"
      },
      "source": [
        "The biggest influence on the performance was when we removed the duplicates. </br>\n",
        "Here, the amount of contradictions was way lower, therefore the model performed better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc99pjUBhxba"
      },
      "source": [
        "### Task 1.9.1 Overall conclution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyaXdzMkhZyo"
      },
      "source": [
        "Overall I think that the used data wasn't the right data to use for this task.\n",
        "  - We also needed to clean up a lot of the images, removing duplicates and blank images. This resulted in better performance.\n",
        "</br> What first seemed like a local minimum, could possible be a global minimum.\n",
        "\n",
        "  - It would be a good approche to use the results of Task2, for filtering the images."
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4H1rkd-a6ok1"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}